# 前言

1. CentOS环境配置

   - CentOS虚拟机：2G内存、50G磁盘空间

     - /boot=1G + est4
     - swap=4G
     - /=45G

   - 关闭防火墙

     ```sh
      # 查看防火墙状态
     systemctl status firewalld
     # 启动防火墙 
     systemctl start firewalld
     # 禁用防火墙
     systemctl stop firewalld
     # 设置开机启动 
     systemctl enable firewalld
     # 停止并禁用开机启动
     sytemctl disable firewalld
     ```

   - 设置为固定IP：`/etc/sysconfig/network-scripts/ifcfg-enp0s5`

     ```sh
     BOOTPROTO=static
     # 设置静态IP:同一个网络中服务器的唯一地址
     IPADDR=10.211.55.201
     # 网管配置: 是一个网络连接到另一个网络的“关口”
     GATEWAY=10.211.55.1
     # 子网掩码: 用于从IP地址中提取网络号或主机号
     NETMASK=255.255.255.0
     ```

   - 执行root命令不输入密码：` /etc/sudoers`

     ```sh
     %wheel  ALL=(ALL)       ALL
     # 在这行后面添加一行
     panda   ALL=(ALL)       NOPASSWD: ALL
     ```

   - 修改主机名称：`/etc/hostname`

   - 添加主键IP映射：`/etc/hosts`

   - 自定义环境变量配置文件：从`/etc/profile`配置文件中会加载`/etc/profile.d/`目录中的sh文件，所以一般会在当前目录中自定义所需要的sh配置文件；

   - scp：实现服务器与服务器之间的数据拷贝

     ```sh
     scp -r $parent_dir/$file_name $user@$host:$parent_dir/$file
     
     # 案例
     scp -r /opt/module/jdk8 panda@hadoop202:/opt/module/jdk8
     scp -r panda@hadoop201:/opt/module/jdk8 /opt/module/jdk8
     ```

     > - -r：递归
     > - 源文件
     > - 目标服务器文件目录

   - rsync：远程同步工具，用户备份和镜像。特点是速度快，避免复制相同内容和支持符号链接的 特点，与scp比较同步只对有差异的文件做更性，cp是全量拷贝；

     ```sh
     rsync -av $parent_dir/$file_name $user@$host:$parent_dir/$file
     ```

     > -a：归档拷贝
     >
     > -v：显示复制过程

2. SSH无密码登录

   ```sh
   # 生产秘钥对:在家目录中.ssh文件夹中
   ssh-keygen -t rsa
   # 讲公钥复制到需要免密的服务器
   ssh-copy-id 服务器IP
   ```

3. Linux环境安装JDK8

   ```sh
   export JAVA_HOME=<jdk8>
   export PATH=$PATH:$JAVA_HOME/bin
   export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
   ```

# 第一章 大数据概述

## 1.1 大数据特点

在以电子机计算机为代表的现代信息技术出现后，电子数据又成为一种新的战略资源。在1998年美国SGI首席科学家约翰·马西在报告中指出：随着数据量的快速增长，必将出现数据难理解、难获取、难处理和难组织等四个难题，并用“Big Data（大数据）”来描述这一挑战；全球范围内，研究发展大数据技术、运用大数据推动经济发展、完善社会治理、提升政府服务和监管能力正成为趋势。大数据的5V特点：

1. Volume（大量）：
2. Velocity（高速）：
3. Variety（多样）：数据形式不仅是文本形式，更多的是图片、视频、音频、地理位置信息等多种数据类型并且大多是个信号数据；
4. Value（低价值密度）：
5. Veracity（真实性）：

## 1.2 大数据岗位

[![5gtQfA.png](https://z3.ax1x.com/2021/10/23/5gtQfA.png)](https://imgtu.com/i/5gtQfA)

1. **平台团队(运维团队)**：运维工程师最基本的职责都是负责服务的稳定性，确保服务可以7*24H不间断地为用户提供服务，负责维护并确保整个服务的高可用性，同时不断优化系统架构提升部署效率、优化资源利用率；
2. **数据仓库团队**：
   - 负责进行数据仓库需求分析、方案设计、ETL装载过程设计，前台分析展现设计，BI报表开发；
   - 配合按业务分析需求进行建模，包括概念模型，逻辑模型及物理模型;
   - 负责数据仓库的建立和维护，解决现有业务需求以及未来面临高速增长的业务数据;
3. **实时计算团队**：实时计算引擎/平台的研发工作，支撑每秒百万吞吐的复杂分析业务，包括实时推荐/实时报表/实时数据交换等核心业务。
4. **数据挖掘团队**：分布式计算，线性扩展，保证性能，一键发布挖掘模型，模型库提高知识复用，减少重复投入，支持跨库查询，统一控制数据访问权限，训练自动化、模型自学习
5. **BI团队**：主要是是做商业智能分析，对Sap的企业管理数据做分析，为领导决策，做预算，做企业战略分析用的工具等。

## 1.3 大数据技术栈

[![5g2HDe.png](https://z3.ax1x.com/2021/10/23/5g2HDe.png)](https://imgtu.com/i/5g2HDe)

- 数据来源层：三种数据来源
- 数据传输层：大数据框架处理数据的框架
- 数据存储层：数据接受完成后进行数据的存储
- 资源管理层：资源调度
- 数据计算层：实时计算和离线计算，并且可以数据查询
- 任务调度层：定时执行
- Zookeeper：整个数据平台的配置和调度
- 业务模型层：业务模型的课可视化

## 1.4 大数据技术栈案例

[![5gRlVJ.png](https://z3.ax1x.com/2021/10/23/5gRlVJ.png)](https://imgtu.com/i/5gRlVJ)](https://imgtu.com/i/5g2HDe)

# 第二章 Hadoop入门

## 2.1 Hadoop介绍

1. **Hadoop是什么**：Hadoop是由Apache基金会开源的分布式系统基础架构，主要解决海量数据的存储和海量数据的分析计算；从广义上讲，Hadoop通常指Hadoop生态圈：围绕数据存储和数据分析的一系列大数据技术栈
2. **Hadoop[发展历史]([Hadoop发展历史简介 - 玄苦 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xuanku/p/hadoop_history.html))**
   - 2002~2004：`Doug Cutting`联合了`Mike Cafarella`决定开发一个开源搜索引擎，项目名称`Nutch`。做到亿量级网页抓取；
   - 2004~2006：Google公布了GFS和MapReduce两篇论文，他们参考论文用Java开发，到2004年的时候, 已经差不多能在40台左右的机器上运行了。
   - 2005年Hadoop作为Lucene的子项目引入Apache基金会2
   - 2006年3月：MapReduce和Nutch Distributed File System分别被纳入到Hadoop项目中，Hadoop项目诞生，标志着大数据时代来临
   - 2008：Google的工程师`Christophe Bisciglia`成立了商业化Hadoop的公司Cloudera：提供了CDH的Hadoop版本：整合管理界面，做到配置可视化，并集成大数据框架
   - 2011：Yahoo讲Hadoop团队成立了子公司`Hortonworks`，对应产品HDP,其特点是文档好，现已被Cloudera公司收购并推出新的品牌CDP
3. **Hadoop三大发型版本**
   - Apache Hadoop：最原始（最基础）的版本
   - Cloudera Hadoop：最早将Hadoop商用的公司，提供Hadoop的商用解决方案，主要是包括支持、咨询服务、培训。
   - Hortonworks Hadoop：主打产品是Hortonworks Data Platform（HDP）还包括了Ambari一款安装和管理系统。
4. **Hadoop特点**
   - 优点：
     - 高可靠性：Hadoop地城维护多个数据副本，即使Hadoop某个计算原始或存储出现故障也不会导致数据丢失；
     - 高扩展性：在集群间分配任务数据，可动态的扩展数以千计的节点；
     - 高效性：在MapReduce思想下，Hadoop是并行工作的，可以加快任务处理速度；
     - 高容错性：能都自动讲失败任务重新分配；
   - 缺点：
     - 不适用于低延迟数据访问。
     - 不能高效存储大量小文件。
     - 不支持多用户写入并任意修改文件。

## 2.2 Hadoop组成

| Hadoop1.X                                                    | Hadoop2.X                                                    | Hadoop3.X   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ----------- |
| MapReduce：计算+资源调度<br />HDFS：数据存储<br />Common：辅助工具 | MapReduce：计算<br />Yarn：资源调度<br />HDFS：数据存储<br />Common：辅助工具 | 同Hadoop2.X |

1. **HDFS**：Hadoop Distributed File Systemax，是一个分布式文件系统：与Linux系统种文件系统类似，不同的是HDFS可以管理多个服务器种的文件；

   - NameNode：存储文件的元数据（文件名、文件目录、文件数学）以及每个文件的块列表和块所在的DataNode
   - DataNode：在单个服务器系统种存储文件文件数据块以及数据块的校验值；
   - SecondaryNode：主要作用是NameNode的备份，定时更新

2. **Yarn**：Yet Another Resource Negotiator是一种资源协调者，如下图是Yarn架构图：客户端向ResourceManager提交任务，RM将任务分配给具体服务种的NodeManager，NM讲任务交给APPMaster，APPMaster向RM申请资源（CPU、内存等等），APPMaster获得资源后开辟资源执行具体的MapTask（并且可以跨节点分配任务）

   [![5ggEZj.png](https://z3.ax1x.com/2021/10/23/5ggEZj.png)](https://imgtu.com/i/5ggEZj)

3. **MapReduce**：将计算过程分为两个阶段：Map和Reduce

   - Map阶段：并行处理输入数据
   - Reduce阶段：对Map结果进行汇总

## 2.3 HDFS、Yarn、MapReduce关系

[![5g2aAs.png](https://z3.ax1x.com/2021/10/23/5g2aAs.png)](https://imgtu.com/i/5g2aAs)

1. Client发出请求：要求在集群服务器中查询服务器中的指定资源
2. ResourcesManager：收到请求，RM找一台节点，该节点Container中的APPMaster开启一个任务
3. APPMaster向RM进行资源申请，RM把有资源的节点进行分配，节点中的Container开启MapTask
4. 查询出结果汇总写入到HDFS

## 2.4 Hadoop环境安装

1. **前期准备**

   - Linux模板虚拟机（IP、hostname、配置文件）
   - JDK8安装并配置环境变量

2. **Hadoop安装**

   ```sh
   export HADOOP_HOME=<hadoop3>
   export PATH=$PATH:$HADOOP_HOME/bin
   export PATH=$PATH:$HADOOP_HOME/sbin
   ```

3. **Hadoop安装目录说明**

   - /bin
     - hdfs
     - yarn
     - mapped
   - /sbin
     - start-dfs
     - start-yarn
     - mr-jobhistory-daemond
   - /etc：配置文件
     - core-site.xml
     - hdfs-site.xml
     - mapped-site.xml
     - yarn-site.xml
     - workers.xml
   - share：官方提供案例

4. **Hadoop运行模式**

   - 本地模式：指单台服务器上搭建的单机版Hadoop，但是数据存储在Linux本地
   - 伪分布式模式：是运行在单服务器，数据存储在H DFS上
   - 完全分布式模式：多台主机组成的服务器集群 

## 2.3 Hadoop集群配置

1. 准备三台Hadoop服务器：hadoop201、hadoop202、hadoop203

2. Hadoop服务规划案例

   > - NameNode和SecondaryNameNode不要安装在同一台服务器；
   > - ResourceManager很消耗内存：不要和NameNode、SecondaryNameNode配置在同一台服务器

   |      | hadoop201                  | hadoop202                                  | hadoop203                          |
   | :--: | -------------------------- | ------------------------------------------ | ---------------------------------- |
   | HDFS | DataNode<br />**NodeName** | DataNode<br /><br />                       | DataNode<br />**SecondaryManager** |
   | YARN | NodeManager<br /><br />    | NodeManager<br />**ResourceManager**<br /> | NodeManager<br /><br />            |

3. 配置文件说明：Hadoop配置文件分两类，默认配置文件和自定义配置文件

   - 默认配置文件：一般不做修改，

     | 默认配置文件       | 配置文件位置                                            |
     | ------------------ | ------------------------------------------------------- |
     | core-default.xml   | hadoop-common-xxx.jar/core-default.xml                  |
     | hdfs-default.xml   | hadoop-hdfs-xxx.jar/hdfs-default.xml                    |
     | yarn-default.xml   | hadoop-yarn-common-xxx.jar/yarn-default.xml             |
     | mapred-default.xml | hadoop-mapreduce-client-core-xxx.jar/mapred-defualt.xml |

   - 自定义配置文件：`HADOOP_HOME/etc/hadoop`目录中

     | 配置文件        | 配置项                                                       |
     | --------------- | ------------------------------------------------------------ |
     | core-site.xml   | fs.defaultFS：设置NameNode所在服务<br />hadoop.tmp.dir：设置数据存储目录<br />hadoop.http.staticuser.user： |
     | hdfs-site.xml   | dfs.namenode.http-address<br />dfs.namenode.secondary.http-address |
     | yarn-site.xml   |                                                              |
     | mapred-site.xml |                                                              |

4. 集群配置说明

   - core-site.xml

     ```xml
     <?xml version="1.0" encoding="UTF-8"?>
     <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
     
     <configuration>
       <!-- hadoop201: NameNode -->
       <property>
         <name>fs.defaultFS</name>
         <value>hdfs://hadoop201:8020</value>
       </property>
     
       <!-- hadoop201: 数据存储目录 -->
       <property>
         <name>hadoop.tmp.dir</name>
         <value>/opt/module/hadoop3/data</value>
       </property>
     
       <!-- 配置HDFS网页登陆使用的静态用户为panda 
       <property>
         <name>hadoop.http.staticuser.user</name>
         <value>panda</value>
       </property>
     	-->
     </configuration>
     ```

   - hdfs-site.xml

     ```xml
     <?xml version="1.0" encoding="UTF-8"?>
     <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
     <configuration>
       <!-- NameNode web访问地址 -->
       <property>
         <name>dfs.namenode.http-address</name>
         <value>hadoop201:9870</value>
       </property>
       <!-- SecondaryNameNode web访问地址 -->
       <property>
         <name>dfs.namenode.secondary.http-address</name>
         <value>hadoop203:9868</value>
       </property>
     </configuration>
     ```

   - yarn-site.xml

     ```xml
     <?xml version="1.0"?>
     <configuration>
       <!-- 指定MR 走shuffle -->
       <property>
         <name>yarn.nodemanager.aux-services</name>
         <value>mapreduce_shuffle</value>
       </property>
     
       <!-- 指定resourcesManger地址 -->
       <property>
         <name>yarn.resourcemanager.hostname</name>
         <value>hadoop202</value>
       </property>  
     
       <!-- 环境变量继承 -->
       <property>
         <name>yarn.nodemanager.env-whitelist</name>
         <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
       </property>
     </configuration>
     ```

   - mapred-site.xml

     ```xml
     <?xml version="1.0"?>
     <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
     <configuration>
       <!-- 指定MapRed运行在Yarn上 -->
       <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
       </property>
       <!-- 历史服务器地址 -->
       <property>
       <name>mapreduce.jobhistory.address</name>
       <value>hadoop201:10020</value>
     </property>
     <!-- 历史服务器WEB地址 -->
     <property>
       <name>mapreduce.jobhistory.webapp.address</name>
       <value>hadoop201:19888</value>
     </property>
     </configuration>
     ```

5. 将配置分发给另外的hadoop配置中

6. 配置works.xml

   ```sh
   hadoop201
   hadoop202
   hadoop203
   ```

7. 第一次启动集群需要初始化：需要在hadoop201节点格式化NameNode，格式化NameNode会产生新的集群id，导致NameNode和DataNode的集群id不一致，就是导致集群找不到数据；所以如果集群在运行中报错，需要重新格式化NameNode的话一定要先停止NameNode和DataNode进程，并且要删除所以机器的data和logs目录

   ```sh
   hdfs namenode -format
   ```

8. 启动集群

   - hadoop201启动NameNode服务

     ```sh
     start-dfs.sh
     ```

   - hadoop202启动ResourceManager

     ```sh
     start-yarn.sh
     ```

   - 启动历史服务器

     ```sh
     mapred --deamon start historyserver
     ```

9. 测试集fs

   ```sh
   # 上传小文件
   hadoop fs -mkdir /目录名称
   hadoop fs -put xxx.txt hadoop目录
   # 上传大文件
   hadoop fs -put 上传文件的路径 hadoop目录
   ```

10. WEB地址说明

    - DFS：http://hadoop201:9870/
    - YARN：http://hadoop202:8088/

11. 

# 第三章 Hadoop HDFS

# 第四章 Hadoop MapReduce

# 第五章 Hadoop Yarn

# 第六章 生产调优

# 第七章 源码解析