[TOC]

# 前言



# 第一章 基础知识

## 1.1 线程相关名词解释

### 1. 线程与进程

- **进程**：是程序的一次执行过程；进程由指令和数据组成：指令会加载到CPU中，数据会读写到内存中，在这期间还需要用到磁盘、网络等设备；进程是用来加载指令、管理内存、管理IO，是一个动态概念，是程序在执行过程中分配和管理资源的基本单位，每一个进程都有一个自己的地址空间；

  > - 当一个程序被运行，从磁盘加载这个程序到内存，这时就开启了一个进程
  >
  > - 进程可以理解为一个程序的实例：大部分程序可以同时运行多个进程实例，有的只可以启动一个实例；

- **线程**：是CPU调度和分派的基本单位，它可与同属一个进程的其他的线程**共享**进程所拥有的全部资源；一个进程可以分为一到多个线程，一个线程就是一个指令流，将指令流中一条条的指令以一定的顺序交给CPU执行；

- **进程与线程的对比**：线程是进程的一部分；一个线程只能属于一个进程，而一个进程可以有多个线程；

  > - **根本区别**：进程是操作系统资源分配的基本单位，进程之间是相互独立的，而线程是任务调度和执行的基本单位
  > - **开销方面**：每个进程都有独立的代码和数据空间（程序上下文），进程切换开销大；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程切换开销小；
  > - **所处环境**：在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行）
  > - **内存分配**：系统为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源
  > - **包含关系**：线程是进程的一部分，所以**线程也被称为轻权进程或者轻量级进程**

### 2. 串行、并行与并发

- **串行**：同一时刻只能完成一个任务

  >  只有一个执行单元（单核CPU或单个CPU）中完成多个线程任务，因为CPU同时只有一个线程在执行，所以这些线程会从物理上就只能一个任务、一个任务地执行；

- **并行（parallel）**：同一时间处理多件任务的能力

  > 有多个执行单元（多核CPU）可以同时通过多进程/多线程的方式取得多个任务，并以多进程或多线程的方式同时执行这些任务，从物理上是多个CPU同时让多个任务一起执行，并行是可以提高线程执行效率的；

- **并发（concurrent）**：同一时间应对多件任务的能力

  > 同时应对多个任务，但是不一定同时执行，多件事情堆在一起有执行风险；

### 3. 同步与异步

- **同步**：
- **异步**：

## 1.2 线程与CPU

### 1. CPU结构

<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>主要由运算器、控制器、寄存器三大块组成。运算器就是中央机构里负责执行任务的部门，也就是专门干活的；而控制器就是中央机构的领导小组，针对不同需要，给运算器下达不同的命令；寄存器可以理解为控制器和运算器之间的联络小组，主要工作就是协调控制器和运算器。 

<img src="https://s1.ax1x.com/2020/11/05/B2SKPK.png" alt="B2SKPK.png" border="0" />

### 2. CPU多核缓存架构

<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>为了提高程序运行的性能，现代CPU在很多方面会对程序进行优化。CPU的处理速度是很快的，内存的速度次之，硬盘速度最慢。在cpu处理内存数据中，内存运行速度太慢，就会拖累cpu的速度。为了解决这样的问题，cpu设计了多级缓存策略。

<img src="https://s1.ax1x.com/2020/11/05/B29SpT.png" alt="B29SpT.png" border="0" />

- **L1 Cache (一级缓存)**是CPU第一层高速缓存，分为数据缓存和指令缓存。它是封装在CPU芯片内部的高速缓存，用于暂时存储CPU运算时的部分指令和数据，存取速度与CPU主频相近。内置的L1高速缓存的容量和结构对CPU的性能影响较大，一级缓存容量越大，则CPU处理速度就会越快，对应的CPU价格也就越高。一般服务器的CPU的L1缓存的容量通常在32-4096K
- **L2 Cache (二级缓存)**是CPU外部的高速缓存，由于L1高速缓存的容量限制，为了再次提高CPU的运算速度，在CPU外部放置一高速存储器，即二级缓存。像一级缓存一样，二级缓存越大，则CPU处理速度就越快，整台计算机性能也就越好。一级缓存和二级缓存都位于CPU和内存之间，用于缓解高速CPU与慢速内存速度匹配问题。
- **L3 Cache (三级缓存)** 都是内置的，它的作用是进一步降低内存延迟，同时提升大数据量计算时处理器的性能。具有较大L3缓存的处理器，能提供更有效的文件系统缓存行为及较短的消息和队列长度。一般多核共享一个L3缓存。

### 3. 为什么要CPU缓存

<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>CPU的频率太快，快到主存根本跟不上，这样在处理周时钟期内，CPU常常需要等待缓存，严重浪费资源。CPU Cache的出现为了缓解CPU和内存之间速度不匹配的问题；

- 时间局部性：如果某个数据被访问，那么不久的将来它很可能再次被访问（**可能频繁访问统一数据**）；
- 空间局部性：如果某个数据被访问，那么与他相邻的数据很快也有可能被访问（**个属性的相邻属性可能被访问**）；

### 4. CPU缓存一致性（MESI）

<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>规定CPU中每个缓存行（caceh line）使用4种状态进行标记（使用额外的两位(bit）表示）；用于保证多个CPU cache之间缓存共享数据的一致，因为每个CPU都有自己的缓存，容易导致一种情况就是：如果多个CPU的缓存（多CPU读取同样的数据进行缓存，进行不同运算后，写入内存中）中都有同样一份数据，那这个数据要如何处理呢？已谁的为准？ 这个时候就需要一个缓存同步协议了！

<img src="https://s1.ax1x.com/2020/11/05/B29k7R.png" alt="B29k7R.png" border="0" />

- **修改态 (Modified)** ：代表该缓存行中的内容被修改了，并且该缓存行只被缓存在该CPU中。这个状态的缓存行中的数据和内存中的不一样，在未来的某个时刻（当其他CPU要读取该缓存行的内容时。或者其他CPU要修改该缓存对应的内存中的内容时）它会被写入到内存中；当被写回主存之后，该缓存行的状态会变成独享（`exclusive`)状态。
- **专有态 (Exclusive)** ：代表该缓存行对应内存中的内容只被该CPU缓存，其他CPU没有缓存该缓存对应内存行中的内容。这个状态的缓存行中的内容和内存中的内容一致。该缓存可以在任何其他CPU读取该缓存对应内存中的内容时变成S状态。或者本地处理器写该缓存就会变成M状态。

- **共享态 (Shared)** ：该状态意味着数据不止存在本地CPU缓存中，还存在别的CPU的缓存中。这个状态的数据和内存中的数据是一致的。当有一个CPU修改该缓存行对应的内存的内容时会使该缓存行变成 I 状态。
  - **无效态 (Invalid)**： 此缓存无效，需要从主内存中重新读取。

### 5. **引起缓存状态改变的方法**

- 状态转换图：**local read** : 读取本地缓存中数据、**local write** : 将数据写到本地缓存中、**remote read** : 读取内存数据、**remote write** : 将数据写入到主存中

<img src="https://s1.ax1x.com/2020/11/05/B29p1U.png" alt="B29p1U.png" border="0" />

- **状态之间的相互转换关系**

  |               | local read | local write | remote read | remote write |
  | ------------- | :--------: | :---------: | :---------: | :----------: |
  | **Modified**  |   [M](#)   |   [M](#)    |   [S](#)    |    [I](#)    |
  | **Exclusive** |   [E](#)   |   [M](#)    |   [S](#)    |    [I](#)    |
  | **Shared**    |   [S](#)   |   [M](#)    |   [S](#)    |    [I](#)    |
  | **Invalid**   |  [E/S](#)  |   [M](#)    |   [I](#)    |    [I](#)    |

### 6. CPU乱序执行优化

- 指处理器为了提高运算速度而做出违背代码原有顺序的优化
- 在多核处理器下, 乱序执行优化有一定风险

## 1.3 线程与JVM



## 1.4 并发的优势与风险

- **优势**
  - **速度**：同时处理多个请求，响应更快，复杂的操作可以分成多个进程同时进行；
  - **设计**：程序设计在某些设计下更简单，也可以有更多的选择；
  - **资源利用**：CPU可以在等待IO时候处理其他事情；
- **风险**
  - **安全性**：多个线程共享数据时候可能产生于期望不相符的结果；
  - **活跃性**：某个操作无法继续进行下去的时候，就会发生活跃性问题：如死锁、饥饿等问题
  - **性能**：线程过多的时候会使得CPU频繁切换，调度时间增多；同步机制消耗过多内存；

# 第二章 Java线程基础

## 2.1 创建线程

## 2.2 线程状态

## 2.3 线程状态转换

# 第三章 线程并发与线程安全

## 3.1 线程与安全

## 3.2 原子类

## 3.3 线程控制

## 3.4 线程池

# 第四章 高并发处理思路与手段

## 4.1 扩容

## 4.2 缓存

## 4.3 队列

## 4.4 应用拆分

## 4.5 限流

## 4.6 服务降级与服务熔断

## 4.7 数据库切分,分库分表

## 4.8 高可用的一些手段

